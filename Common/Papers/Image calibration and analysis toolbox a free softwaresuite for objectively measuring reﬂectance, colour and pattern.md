# 이미지 보정 및 분석 툴박스 – 반사율(reflectance), 색(colour) 및 패턴(pattern)을 객관적으로 측정하기 위한 무료 소프트웨어 모음

**Jolyon Troscianko*, Martin Stevens**
Centre for Ecology & Conservation, College of Life & Environmental Sciences, University of Exeter, Penryn Campus, Penryn TR10 9FE, UK

---

> 이 논문은 영국생태학회(John Wiley & Sons Ltd가 대행)에서 발행하는 *Methods in Ecology and Evolution* 2015, 6: 1320–1331에 실린 오픈 액세스(CC BY) 논문입니다. 원문 DOI: 10.1111/2041-210X.12439

---

## 요약(Summary)

1. 색(color), 패턴(pattern), 형태(morphology)에 대한 정량적 측정은 다양한 학문 분야에서 점점 더 중요한 의미를 갖는다. 디지털 카메라는 손쉽게 구할 수 있고 이미 이러한 측정을 위해 널리 사용되며, 분광측정(spectrometry) 같은 다른 기법에 비해 여러 장점을 가진다. 그러나 시판용 소비자 카메라는 인간 시각에 맞춘 이미지를 만들도록 설계되어 있어, **보정되지 않은 사진**은 신뢰할 수 있는 정량 측정에 사용할 수 없다. 여전히 많은 연구가 이 점을 간과하고 있으며, 이러한 문제를 아는 연구자들조차 사진으로부터 객관적 측정을 수행할 **사용성 높은 도구의 부재**로 어려움을 겪는다.

2. 우리는 다양한 카메라 브랜드의 RAW 파일로부터 **광휘(radiance)에 대해 선형(linear)인 이미지**를 생성하고, 자외선(UV) 사진을 포함한 다중분광(multispectral) 카메라의 채널을 결합할 수 있는 **이미지 처리 툴박스**를 개발하였다. 이미지는 하나 이상의 회색 기준(gray standards)을 이용해 표준화(normalisation)되어 조명 조건을 보정한다. 이를 통해 **일반 소비자용 카메라**로도 반사율과 색을 객관적으로 측정할 수 있다. 더 나아가 카메라의 **스펙트럼 감도(spectral sensitivities)**가 알려져 있다면, 소프트웨어는 이미지를 다양한 동물의 **시각계(cone-catch values)**에 대응하도록 변환할 수 있어, 인간 및 비인간 시각계를 모델링할 수 있다. 또한 툴박스는 휘도(luminance, lightness), 색, 패턴 정보를 추출할 수 있는 이미지 분석 도구를 제공한다. 모든 처리는 **8‑bit**가 아닌 **32‑bit 부동소수점** 이미지에서 수행되며, 이는 정밀도를 높이고 반올림 오류나 픽셀 포화에 따른 데이터 손실 가능성을 줄이며, 광택(shiny) 또는 형광(fluorescent) 특성을 가진 객체의 측정도 용이하게 한다.

3. 본 소프트웨어로 테스트한 모든 카메라는 **각 이미지 내와 다양한 노출 시간 전반에서 선형 응답**을 보였다. **콘 캐치(cone‑catch) 매핑 함수**는 매우 견고하여, 이미지를 여러 동물 시각계로 변환했을 때 **분광광도계 기반 추정치와 높은 일치**를 보였다.

4. 우리의 이미지 처리 툴박스는 오픈 소스 소프트웨어인 **ImageJ**의 추가 모듈로 **무료 공개**된다. 우리는 이 도구가 생물학 전반, 특히 **동물·식물의 시각 신호**를 정량화하려는 연구자들에게 디지털 카메라의 적절한 활용을 크게 증진시킬 것으로 본다.

**핵심어(Key-words)**: 동물 채색(animal coloration), 카메라 보정(camera calibration), 색 측정(colour measurement), 색 시각(colour vision), 의사소통(communication), 콘 캐치 양자(cone‑catch quanta), 이미지 처리(image processing), 패턴 분석(pattern analysis), 신호(signalling), 분광계(spectrometer)

---

## 서론(Introduction)

외양(appearance)의 **객관적 측정**은 생물학의 수많은 분야에서 필수적이다. 이는 다양한 분류군에 걸친 **시각 신호의 기제와 기능**, 의사소통과 위장(camouflage)에 관한 연구, 인간 및 비인간 시각 연구, 고생물학, 법과학(forensics), 의학 진단 등 응용 분야에까지 이른다. 이러한 형질을 엄밀히 분석하는 능력은 그 **진화와 기능**을 이해하기 위해 필수적이다.

이 목적을 위해 다양한 방법이 존재하지만, 생태·진화 연구에서 가장 널리 쓰이는 기법은 아마 **분광측정(spectrometry)**일 것이다. 그러나 이전 논의(Stevens et al., 2007; Stevens, Stoddard & Higham, 2009)에서 지적되었듯, 분광측정에는 여러 중대한 한계가 있다. 특히 **소규모 지점(point) 표본**으로 제한되어 2D 또는 3D의 **패턴 특성**을 분석하기에 부적합하고, 현장 적용이 어렵고, 표본에 대한 **근접 접촉**이 필요하며, **측정 각도**나 **프로브-표본 간 거리** 변화에 매우 민감하다(White et al., 2015).

디지털 카메라는 이에 대한 대안으로, 다양한 상황에서 데이터를 수집하는 **다재다능한 도구**이다. 대규모 소비자 시장 덕분에 가격은 낮아지고 해상도와 **동적 범위(dynamic range)**는 높아지는 추세다. 이는 여전히 전문 장비이고 많은 연구자 예산 범위를 넘어서는 **분광계**와 대비된다. 디지털 카메라는 다른 방법의 한계를 극복하며, 실험실과 현장에서 모두 사용하기 쉽고, 표본을 만지거나 가깝게 접근할 필요 없는 **비침습성**을 제공한다. 또한 전체 색 패턴, 시각 장면, 객체의 2D/3D 특성을 분석하기 위한 **컴퓨터 과학적 접근**을 폭넓게 구현할 수 있다(Shapiro & Stockman, 2001; Stevens & Cuthill, 2006; Stoddard, Kilner & Town, 2014; Allen & Higham, 2015). 오늘날에는 **자외선(UV)** 감응 카메라 사용도 비교적 손쉽다. 많은 동물이 UV를 지각한다는 점에서 이는 중요하다.

그럼에도 디지털 카메라와 이미지를 **적절히** 사용하려면 여러 고려사항과 절차가 필요하다(Stevens et al., 2007; Stevens, Stoddard & Higham, 2009; Pike, 2011). 요약하면, 사진은 **저(低) 동적 범위** 디스플레이 매체에서 사람 눈으로 보기 좋게 최적화되어 있어, **광강도/광휘(radiance) 변화에 대한 비선형(non‑linear) 응답**을 갖는다. 결과적으로 **비선형 이미지 데이터**는 실제 물체 값을 거의 항상 과소 또는 과대 추정한다. 또한 사진은 **조명 조건 차이**를 보정하기 위해 표준화가 필요하다. 더 나아가 카메라의 **스펙트럼 감도**를 측정하려면 광휘에 대한 **선형 응답**이 전제되어야 하며(Lovell et al., 2005; Stevens et al., 2007; Pike, 2011; Garcia et al., 2014), 그래야 이미지를 동물의 **시각계 공간**으로 변환할 수 있다. 이러한 이유로, 적절한 **보정(calibration)** 없이 디지털 이미지를 사용해 밝기, 색, 패턴을 사진 내부 혹은 사진 간에 **객관적으로 측정**해서는 안 된다(Stevens et al., 2007). 그럼에도 동물과 식물의 시각 신호를 다룬 연구들 가운데 상당수가 여전히 이러한 문제를 다루지 않아 **부정확하거나 결함 있는 데이터**를 낳는다. 한편 완전히 보정된 카메라로 다양한 시각 신호를 분석한 연구들도 있지만(e.g., Lovell et al., 2005; Spottiswoode & Stevens, 2010; Allen, Stevens & Higham, 2014; Stevens, Lown & Wood, 2014a; Stoddard, Kilner & Town, 2014), 여전히 상대적으로 드물다. 또한 많은 연구가 디지털 이미지 분석의 잠재력을 충분히 활용하지 못하는데, 예컨대 데이터를 **동물 시각 지표**로 변환하거나 **객체 패턴**을 분석하는 가능성들이 있다.

궁극적으로 위 문제들의 주요 원인은 **소프트웨어 기술의 후진성**에 있다. 선형화 곡선을 수동으로 생성하려면 보정된 회색 기준(calibrated grey standards)과/또는 **분광복사계(spectroradiometer)** 같은 **고가 장비**와, MATLAB 같은 **유료 소프트웨어**에서의 코딩 기술이 필요하다. 그러나 Chakrabarti, Scharstein & Zickler(2009)는 자유 배포되는 **DCRAW** 소프트웨어(Coffin, 2015)를 올바르게 사용해 RAW 이미지를 추출하면, 많은 카메라 모델에서 **RAW – 광휘 간 선형 관계**를 유지할 수 있음을 보였다. 이는 디지털 이미지로부터 객관적 측정을 수행할 때 중요한 걸림돌을 제거한다. 그럼에도 지금까지 연구자가 자신의 이미지를 **표준화(normalise)**하고, **다중 레이어**(예: 가시광과 UV 채널)를 통합하고, **동물 색 공간**으로 변환하며, 이미지를 **쉽게 측정**하게 해주는 **사용자 친화적 프로그램**은 없었다. 대신 이러한 작업은 때로 **복잡한 계산**을 포함하여 연구자가 **수작업**으로 수행해야 했다. 본 논문에서는 이러한 문제를 해결하기 위해 **오픈 소스 소프트웨어** 기반으로 공개하는 **전용 도구 모음**을 제시한다. 아래에서는 (사용자 가이드 외에) 툴박스 개요를 먼저 제시하고, 이후 RAW 이미지의 선형 입력, 표준화, 동물 콘‑캐치 데이터 변환의 **정확성**을 입증한다.

---

## 이미지 보정 및 분석 툴박스 개요(Image calibration and analysis toolbox overview)

아래는 **Image Calibration and Analysis Toolbox**의 간략 개요이며, 자세한 지침과 예시는 툴박스와 함께 배포되는 **사용자 가이드**에 포함되어 있다. 툴박스는 무료 오픈 소스 **IMAGEJ**(Schneider, Rasband & Eliceiri, 2012)의 추가 모듈(plugin)들이며, 관련 파일을 IMAGEJ의 `PLUGINS` 폴더에 복사하면 된다. 이 툴박스는 **선형 이미지 추출**과 **이미지 보정**을 수행하고, 다양한 **분석 도구**로 측정을 구현한다.

### 장비 체크리스트(Equipment checklist)

인간 가시 범위(약 **400–700 nm**)에서 **반사율(brightness), 색, 패턴**을 **객관적으로** 측정하려면 **RAW**를 생성할 수 있는 소비자용 디지털 카메라, **회색 기준(grey standard)**(1개 이상), **스케일 바(scale bar)**(서로 다른 사진 간 패턴 분석 시 필요)만 있으면 된다. 가시광에 한정된 셋업의 경우, 사진용 회색 기준(대부분의 사진 장비 상점에서 다양한 제품 구매 가능)이면 충분하고 합리적 가격이다. **UV 이미징**의 경우, 기준은 **UV 스펙트럼**(대략 300 nm까지)에서도 회색이어야 한다. 이를 위해 소결 PTFE(폴리테트라플루오로에틸렌, 예: Labsphere의 Spectralon) 회색 기준이 자주 사용되며 **약 5%~99%**의 반사율 값을 제공한다. **인공 조명**은 UV 이미징에서 더 까다롭고, **넓은 스펙트럼**의 단일 광원이 필요하다. 자세한 내용은 사용자 가이드 참조. 이러한 셋업과 본 툴박스를 이용한 측정은 **객관적**이지만, **카메라 특이적(camera‑specific)**이다(즉, 다른 카메라를 사용하면 센서 감도 곡선의 차이로 결과가 약간 달라질 수 있음). **시각계 특이적** 결과를 얻으려면 카메라의 **스펙트럼 감도**가 알려져 있어야 한다. 이러한 감도 측정은 어렵기 때문에, 우리는 툴박스에 여러 카메라 시스템의 **감도 곡선**을 제공했다.

**UV 민감성**은 조류, 파충류, 양서류, 어류, 구각류(stomatopods), 곤충, 일부 포유류 등 많은 분류군에 흔하다. 따라서 이들의 감도 범위를 포괄하려면 **풀 스펙트럼 변환(full‑spectrum‑converted)** 카메라가 필요하다. 이 경우, **가시광 통과 필터**로 촬영한 사진과 **UV 통과 필터**로 촬영한 **두 장의 사진**을 소프트웨어가 결합하여 **비인간 시각계** 모델링에 필요한 파장 범위를 포괄하게 한다.

### 사진 촬영 및 처리(Taking and processing photos)

사진은 반드시 **RAW 형식**으로 촬영하며, 하나 이상의 **회색 기준**(같은 사진 안에 포함하거나, **동일 조명 및 카메라 설정**으로 바로 이어 촬영한 **연속 방법(sequential method)** 사진에 포함; Stevens, Stoddard & Higham, 2009)을 포함해야 한다. 컴퓨터로 사진을 옮긴 뒤 첫 단계는 **다중분광 이미지(multispectral image)**를 생성하는 것이다. 이는 **서로 다른 파장 대역(채널)**에서 촬영된 이미지들의 **스택(stack)**을 의미한다. 표준 컬러 사진은 이미 **R/G/B** 스택이지만, 본 소프트웨어는 그 외 **추가 채널**도 처리할 수 있다. 스크립트는 다양한 입력 옵션을 안내하고, 카메라/필터 조합, 회색 기준의 반사율(%) 값, UV 사진의 경우 가시광–UV 이미지 정합 방법을 지정하게 한다. 표준 필터 조합(예: 표준 **RGB** ‘visible’, 또는 ‘visible & UV’)을 제공하며, 추가 조합은 가이드에 설명된 대로 **구성 파일(configuration file)**을 만들어 지정할 수 있다. 그림 1은 가시광과 UV 사진을 **결합**하는 이미지 준비 과정을 보여준다.

입력 설정을 지정하면, RAW 파일 선택을 안내하고, 관련 채널을 RAW에서 **16‑bit/채널**로 추출하여 스택의 슬라이스들을 **정렬(alignment)**한다. 다음으로 스크립트는 사용자가 회색 기준을 선택하도록 요청하며, 회색 기준 위로 **선택 영역(박스, 원, 다각형 등)**을 그리게 한다. **밝은 장(field) 조명**에서는 **베일 글레어(veiling glare)**를 제어하기 위해 **여러 회색 기준** 사용을 권장한다(아래 참조). 회색 기준 측정치와 정렬 오프셋은 RAW와 함께 `.mspec` 파일에 저장된다. 이 파일은 해당 다중분광 이미지를 다시 불러오는 데 필요한 모든 정보를 담으며, RAW 파일과 **같은 디렉터리**에 있어야 한다.

소프트웨어는 다중분광 스택을 **32‑bit/채널**로 변환한 뒤 **표준화(normalisation)**를 수행해 사진 간 조명 변화를 보정하고 픽셀 값을 **반사율**로 스케일링한다(과정은 약 1초). `.mspec` 이미지를 재오픈하면 연결된 RAW가 자동으로 불러와지고, 채널이 정해진 순서로 배열된 뒤 32‑bit 스택으로 변환되며, 픽셀 표준화와 정렬이 수행된다(채널 수, 해상도, 컴퓨터 성능에 따라 수 초). 이 시점에서 표준화된 이미지에서 **반사율과 색**을 **객관적으로 측정**할 수 있으며, 관심 영역(ROI)을 그려 측정할 부분을 지정할 수 있다. 서로 다른 사진 간 **패턴 분석**에는 이미지가 **동일 스케일(단위 길이당 픽셀 수)**이어야 한다. 자동 스케일링을 쓰려면 이미지상의 눈금자(bar)를 선분 도구로 긋고 키보드 `S`를 눌러 길이를 입력하면 된다. 툴박스는 패턴 측정 전에 이미지 크기를 사용자가 설정한 스케일로 자동 변경한다. 탁란(parasitism) 연구 등에서 새의 **알(egg)** 색과 패턴을 측정하는 경우가 흔하다(e.g., Spottiswoode & Stevens, 2010; Stoddard & Stevens, 2010; Kilner, 2006). 이를 돕기 위해, 툴박스에는 **알 측정 및 선택 도구**가 포함되어 있어 알(또는 유사한 형태)의 외곽을 몇 점 클릭하면 곡률을 모델링하고 **형태·부피** 지표를 계산한다(Troscianko, 2014). 스케일 바와 ROI는 `.mspec`와 함께 저장되며 이후 자동으로 재로드된다. 툴박스의 **배치 처리 도구**는 폴더 내 다수의 `.mspec` 이미지(임의 개수)에 대해 여러 선택 영역의 **색, 휘도, 패턴** 속성을 **자동 측정**한다(그림 1 참조). 측정이 끝나면, **동물 시각 판별 모델**(Vorobyev & Osorio, 1998; Siddiqi et al., 2004)을 이용하여 **콘‑캐치 이미지**에서 색 쌍 간 **JND(Just Noticeable Difference)**를 계산하거나, **패턴 차이 분석** 등을 수행할 수 있다.

---

## 툴박스 기술 설명 및 검증(Toolbox technical descriptions and testing)

### 선형 이미지 추출(Extracting linear images)

RAW 사진은 제조사별 **고유 포맷**으로, 광센서 응답을 **12‑bit 또는 14‑bit**로 보존하며, 파일 확장자도 제조사마다 다르다(예: Canon의 `.CR2`, Nikon의 `.NEF`). 카메라 센서의 **R/G/B 포토센서**는 서로 겹치지 않는 모자이크 형태로 배치되어 있으며, 각 픽셀이 세 색 값을 모두 갖도록 **디모자이킹(demosaicing)**이 필요하다. **DCRAW**(Coffin, 2015)는 대부분의 제조사 RAW를 읽고 디모자이킹을 수행하며, 가장 중요한 점으로 **픽셀 값을 선형**으로 추출하여 **16‑bit 이미지**로 출력한다(Chakrabarti, Scharstein & Zickler, 2009). 이는 Stevens et al.(2007)이 제시한 방식처럼 카메라의 비선형성을 수동으로 계산하여 **선형화 식(linearisation equation)**을 구해야 하는 필요를 없앤다. 우리 툴박스는 **IJ‑DCRAW**(Sacha, 2013) 플러그인을 이용해 DCRAW를 통해 RAW에서 픽셀 데이터를 **선형**으로 추출한다.

### 선형성 방법 검증(Testing linearity methods)

시판 **소비자용 디지털 카메라 8대**를 사용해 추출 이미지의 선형성을 테스트했다. 이들에는 풀 스펙트럼 쿼츠 변환을 거친 **Nikon D7000** 4대(이 중 2대는 Nikon Nikkor 105 mm 렌즈, 1대는 Coastal Optics 60 mm 쿼츠 렌즈, 1대는 Coastal Optics 105 mm 쿼츠 렌즈), 풀 스펙트럼 쿼츠 변환을 거친 **Nikon D90**(Nikon Nikkor 105 mm), 변환하지 않은 **Canon 5D MkII**, 풀 스펙트럼 쿼츠 변환을 거친 **Canon 7D**(둘 다 Canon 50 mm f/1.4 렌즈), 풀 스펙트럼 변환을 거친 미러리스 **Samsung NX1000**(쿼츠 필터 없음, Pentax Asahi Super Takumar 50 mm 장착)이 포함되었다. **8종의 확산형 Spectralon 반사율 기준(2, 5, 10, 20, 40, 60, 80, 99%)**을 어두운 방에서 촬영하였다. 조명은 **Iwasaki eyeColor 아크 램프**를 사용해 표면에 직각으로 2 m 거리에서 조사했으며, **CIE 권고 D65**를 모사하는 광스펙트럼을 갖도록 설계되었다. 램프는 UV 필터를 제거(강철 브러시 드릴 비트로 코팅 제거)하여 **자외선 촬영**과 자연 조명 조건의 재현을 가능하게 했다. 표준 반사율 값은 **Jeti Specbos 1211 UV 분광복사계**로 300–700 nm 범위에서 99% 기준 대비 상대 반사율로 검증했다. 모든 사진은 RAW, **ISO 400**으로 촬영했다. **99% 기준**이 가능한 한 **포화 직전** 수준의 픽셀 값을 갖도록 노출을 정했고, 사용 렌즈 모델에 따라 **조리개 스톱** 전 범위로 7–8장의 사진을 촬영하여 **셔터 속도(적분 시간)** 범위를 넓혔다. 넓은 **동적 범위**에서 픽셀 응답의 선형성을 시험하기 위해 각 채널의 픽셀 값을 보정된 표준 반사율에 대해 모델링했다. 반사율 값은 먼저 각 사진의 **회색 기준 픽셀 평균**으로 곱해(조리개 차이에 따른 **광량 차** 보정) 정규화하여, **이미지 내** 및 **서로 다른 셔터 속도 간**의 선형성 여부를 확인했다.

### 선형성 결과(Linearity results)

**픽셀 값–정규화 반사율** 간 **선형 회귀**는 **8개 표준과 모든 셔터 속도**에서 거의 **완벽한 적합**을 보였다(그림 2). **결정계수(R²)**는 모든 카메라 모델과 색 채널에서 **0.998 초과**(평균 0.999, 중앙값 > 0.999)였다. 이는 DCRAW로 선형 추출한 이미지가 실제로 선형이라는 이전 보고(Chakrabarti et al., 2009; Akkaynak et al., 2014)의 정밀도를 향상해 재확인하는 결과다. 모든 이미지에는 일정 수준의 **노이즈**가 존재하며(센서, ISO 게인, 센서에 도달한 광량에 따른 **포아송 샷 노이즈** 등), RAW는 **음수 값**을 지원하지 않으므로 **0 근처 픽셀 값**은 노이즈로 인해 인위적으로 커져 카메라의 **동적 범위**를 제한한다. 우리의 **최저 반사율(2%)** 기준은 선형성을 유지했지만, **0에 더 가까운 값**은 센서의 **SNR** 저하로 신뢰성이 떨어지고 인위적으로 증가할 수 있다. 이는 소프트웨어로 **어두운 객체**를 측정할 수 없다는 뜻이 아니라, **매우 어두운 객체**와 **아주 밝은 객체**를 **같은 사진**에서 동시에 측정하기 어렵다는 뜻이다(카메라의 동적 범위 한계). 어두운 객체를 측정할 때는 **낮은 반사율**의 회색 기준을 써야 하며, 같은 장면을 **짧은 노출**로 추가 촬영하면 밝은 객체 측정이 가능하다. 이는 **HDR 사진**의 원리와 유사하다. 실무적으로 대부분의 생물학적 객체는 극단적으로 낮은 반사율을 보이지 않는다.

### 표준화(Normalisation)

자연 및 인공 **광원(illuminants)**은 **강도(intensity)**와 **색(color)**이 달라진다(Endler, 1993). 따라서 서로 다른 시간 또는 서식지에서 촬영한 두 사진은 **조명 차이를 보정하지 않으면** 비교가 어렵다(실험실에서도 마찬가지). 디지털 이미지 **표준화**는 각 색 채널을 일정 **반사율 수준**으로 스케일링해 사진 간 조명 차이를 보정한다. 이를 위해 이미지 내 **알려진 반사율**을 갖는 **회색/백색 기준**을 사용하여 채널 응답을 측정하고, 시각계의 **크로매틱 적응(chromatic adaptation)**과 유사하게 보정한다(Stevens et al., 2007). 이는 사진의 **화이트 밸런스**와 유사하지만, **선형 이미지**에서 수행되어야 하며, **비선형** 이미지를 대상으로 **포토 편집 소프트웨어**의 스포이드로 흰점을 맞추는 방식으로는 올바르게 수행되지 않는다. 이상적인 기준은 촬영 파장 범위 전반에서 **평탄한 반사 스펙트럼(회색)**을 가지며, **높이 확산적(Lambertian)**이어야 한다(모든 방향으로 균등 산란). **20–50%** 수준의 회색 기준은 **과노출 위험**이 낮아 장점이 있어 사진에서 흔히 사용된다(Stevens et al., 2007). 반면 **백색 기준(예: 95–99%)**은 **온스크린 히스토그램**으로 노출을 맞추기 쉬운 장점이 있다(히스토그램의 최댓값 피크 관찰). 회색 기준의 **조명 및 카메라에 대한 각도**는 매우 중요하며, 특히 **점광원**(높게 방향성 있는)일수록 그렇다. 측정 대상이 대체로 **평면**(예: 나비 날개)이라면, 회색 기준은 대상과 **같은 평면과 각도**에 두어야 한다. 대상이 더 **복잡한 3D 형태**라면, 기준의 각도는 광원 방향을 기준으로 결정한다(인공 점광원이라면 광원을 정면으로, 자연광이라면 수평 배치 가정). 무엇보다 **사진·처리 간 일관성**이 중요하다. 선형 이미지에서 회색 기준은 조명 **색 변화**나 (노출 시간이 통제되었다면) **강도 변화**를 측정하는 데도 쓰일 수 있다(선형 RGB 비율로 조명 색, 사진 간 강도; Lovell et al., 2005; Arenas, Troscianko & Stevens, 2014).

툴박스는 선형 픽셀 값 `V_linear`, 회색 기준 반사율(%) `S`, 최댓값(부호 없는 **16‑bit**의 최대값 **65,535**), 회색 기준 픽셀 평균 `G`로부터 **표준화 픽셀 값** `V_norm`을 다음과 같이 계산한다:

[ V_{\text{norm}} = V_{\text{linear}} \times \left( \frac{S}{100} \right) \times \frac{65,535}{G} \quad (\text{eqn 1}) ]

#### 다중 회색 기준(Multiple grey standards)

어떤 렌즈도 내부 반사를 완전히 제거할 수 없으며, 원치 않는 광원이 센서로 스며들어 **광학적 베일 글레어(optical veiling glare)**를 유발한다(McCann & Rizzi, 2007). 이는 태양 근방을 촬영할 때 **랜즈 플레어**처럼 두드러지게 나타나기도 하지만, 덜 극단적인 경우에는 **육안으로 탐지하기 어려울** 수 있다. 베일 글레어는 특히 **밝은 장(field)** 조건과 **UV 필터** 사용 시 더 흔하며, **블랙 포인트**를 올리고 카메라 **동적 범위**(사진 대비)를 줄인다. 사진의 **블랙 포인트**를 계산하려면 최상·최하단에 가까운 **두 개 이상**의 회색 기준(이상적으론 **검정**과 **백색**)이 필요하다. 이에 따라 툴박스의 표준화 절차는 **임의 개수**의 회색 기준을 활용해 **블랙 포인트 추정**이 가능하도록 했다. 소프트웨어는 사용자가 기준의 반사율을 입력한 뒤 각 기준 위에 선택 영역을 그리게 하고, 측정된 기준 평균과 입력 반사율 사이의 **선형 회귀**를 실시한다. 이후 **직선식**(eqn 1에 **절편** 추가)으로 **표준화 픽셀 값**을 계산한다. 기준을 2개 초과 사용할 경우 적합도 R²가 **0.98 미만**이면 경고한다. 기준이 둘 이상 없고 **베일 글레어**가 우려되는 경우, 툴박스는 채널 **히스토그램**의 **하위 0.5%** 픽셀이 **0.5% 반사율**이라고 가정해 블랙 포인트를 추정할 수 있다(최저 픽셀 하나는 노이즈에 취약하므로 사용하지 않음).

#### 연속 방법(The sequential method)

때로 측정 대상 이미지에 **기준을 직접 포함**할 수 없다(예: 자유 생활 동물 촬영). 이 경우 툴박스는 대상과 **동일 조건**으로 **연속해서 촬영**한 **별도의 사진**에서 회색 기준을 선택하는 옵션을 제공한다(Stevens, Stoddard & Higham, 2009). 이 옵션을 사용할 때는 두 사진 사이에 **조명 변화**나 **카메라 설정 변화**가 없어야 하므로, 가능한 한 **빠르게** 연속 촬영하고, **변덕스런 구름** 같은 **가변 조명**을 피해야 한다. 자세한 내용은 가이드 참조.

### 콘‑캐치 값으로의 매핑(Mapping to cone‑catch values)

시각 신호를 분석하는 많은 연구는 동물 시각계의 **예상 광수용체(cone) 응답(콘‑캐치 값)**을 계산하고, 이를 추가 모델링에 활용한다. 카메라의 **R/G/B 채널 감도**는 모델마다 다르고 인간의 **장·중·단파(L/M/S)** 수용체와 정확히 일치하지 않는다. 따라서 카메라+렌즈 조합이 생성하는 색은 **디바이스 의존적(device‑dependent)**이며, 카메라 색에서 **표준 색도값** 또는 **시각계 특이 데이터**(예: LMS, **CIE XYZ**, 혹은 **콘‑캐치 값**)로 변환하는 **매핑 함수**가 필요하다(Hong, Luo & Rhodes, 2000; Westland, Ripamonti & Cheung, 2004; Lovell et al., 2005; Stevens & Cuthill, 2006; Stevens et al., 2007; Pike, 2011). 이론적으로 이러한 함수는 **오차**를 수반하는 **추정**이며, 같은 조명에서 **서로 다른 스펙트럼**이 **같은 RGB**를 내고 **다른 LMS**를 낼 수 있는 **메타머리즘(metamerism)**을 배제할 수 없다. 특히 반사 스펙트럼의 **급격한 단계 변화**는 메타머리즘을 악화시킨다. 그러나 **자연 스펙트럼**은 대체로 충분히 **매끈(smooth)**하여 **저차 다항식(polynomial)** 매핑으로 **매우 낮은 오차**의 정확도를 얻을 수 있다(Hong, Luo & Rhodes, 2000; Lovell et al., 2005; Stevens et al., 2007).

우리 툴박스는 **자연 스펙트럼 라이브러리**에서 특정 조명 하의 카메라 **RGB**와 목표 시각계 **콘‑캐치 값**(예: 인간 **LMS** 또는 **CIE XYZ**, 비인간 포토레셉터)을 **추정**하여 **매핑 함수**를 생성한다. 예를 들어 장파 수용체의 콘‑캐치 양자(quanta) (L_c)는 다음과 같이 계산한다:

[ L_c = \sum_{k=\min}^{\max} l_k Q_k I_k \quad (\text{eqn 2}) ]

여기서 (l_k)는 장파 감도, (Q_k)는 시료의 **스펙트럼 반사율**, (I_k)는 파장 (k)에서의 **조명 스펙트럼 복사휘도**이다. 그런 다음 콘‑캐치 양자는 다음과 같이 **정규화**하여 (L_n)을 얻는다(조명 (I) 하의 **회색 표면**이 모든 채널에서 **동일 콘‑캐치**를 갖도록 하는 **von Kries 계수법** 기반 색 항등성을 반영; 분광 반사율 기반 방법에서도 표준):

[ L_n = \frac{L_c}{L_{wr}} \quad (\text{eqn 3}) ]

여기서 (L_{wr})은 **백색 기준**에 대해 계산한 콘‑캐치 양자이다. 그 다음 각 수용체 채널에 대해 **다중 회귀** 접근으로 카메라 응답에서 수용체 값을 예측하는 **매핑 함수**를 만든다. 다항식의 **상호작용 항**과 **변환** 수는 다양할 수 있다(Hong, Luo & Rhodes, 2000). 예를 들면:

[ L = a_1 R + a_2 G + a_3 B + a_4 RG + a_5 RB + a_6 GB \quad (\text{eqn 4}) ]

[ L = a_1 R + a_2 G + a_3 B + a_4 RG + a_5 RB + a_6 GB + a_7 RGB + a_8 R^2 + a_9 G^2 + a_{10} B^2 \quad (\text{eqn 5}) ]

카메라 색 채널이 **3개(RGB)**이고 수용체도 **3종(L/M/S)**인 경우를 예시로 들었지만, **추가 카메라 채널**이 있으면 이를 항에 포함할 수 있다. 채널이 많아질수록 **모델 규모**가 커지고 **수렴**과 **적용**이 느려질 수 있다. 따라서 콘 매핑 스크립트는 **최대 상호작용 차수(2‑way/3‑way)**, **제곱항 포함 여부**를 설정할 수 있고, **AIC** 또는 **BIC** 기반의 **단계적 모델 단순화(stepwise)**로 **기여가 미미한 항**을 제거해 **과적합(overfitting)**을 줄일 수 있다(BIC가 더 보수적). 한번 모델이 생성되면(카메라×시각계 조합마다 **몇 분** 소요, **1회**만 계산), 각 다중분광 이미지를 **콘‑캐치 양자 이미지**로 변환하는 처리는 **매우 빠르다**(32‑bit 파랑박새(blue tit) 콘‑캐치 기준으로 **15–20 MP/s**, Intel i5 노트북). 카메라 감도 함수를 가이드에 따라 `.csv`로 준비하고 **Generate Cone Mapping Model**을 실행하면, 스크립트가 카메라, 조명(illuminant), 목표 시각계 감도, 자연 스펙트럼 라이브러리, 상호작용 수준, 단순화 프로토콜(옵션)을 순차 지정받고, 카메라 및 수용체 콘‑캐치를 계산한 뒤 **R**(R Core Team, 2013)로 선형 모델을 적합한다. 모델은 R에서 회수되어 툴박스의 다른 기능과 통합되는 스크립트로 컴파일되고, 수용체별 **R²**로 적합도를 제시한다.

카메라의 **색 채널 수**는 매핑하려는 **수용체 수 이상**이어야 하고, **감도 범위**도 동일 파장대를 포괄해야 한다. 예컨대 **RGB 카메라**는 **삼색성 인간**, **이색성 포유류**, **단색성(명채널) 상어**의 콘‑캐치로 신뢰성 있게 매핑할 수 있지만, **자외선**을 보는 종이나 **매우 좁은 스펙트럼** 감도를 가진 종으로는 불가능하다. **모델 R²**는 매핑 품질을 판단하는 지표로 쓸 수 있다.

많은 동물은 인간의 ~400 nm 하한보다 **짧은 파장**까지 본다. 따라서 이들의 시각을 모델링하려면 **가시광 사진**과 더불어 **UV 사진**이 필요하다. 대부분의 카메라 센서는 **UV 차단 필터**를 제거하면 어느 정도 **UV**에도 민감하며(필요하면 UV 투과 필터로 교체), 툴박스에는 변환 전후의 **카메라‑렌즈‑필터 조합**에 대한 **스펙트럼 감도**가 포함되어 있어 동일 장비를 확보한 연구자는 이를 사용할 수 있다(그림 3의 셋업 간 비교). 풀 스펙트럼 변환은 전문 업체에서 수행 가능하며(예: Advanced Camera Services, UK), 경우에 따라 쿼츠판을 재삽입하지 않고도 **센서 위치**를 조정해 **무한대 초점**을 복구할 수 있다(예: [http://www.jolyon.co.uk/2014/07/full-spectrum-nx1000/](http://www.jolyon.co.uk/2014/07/full-spectrum-nx1000/)). 풀 스펙트럼 카메라는 UV에서 근적외선까지 **넓은 파장대**에 민감하지만, 적외선 감도가 **UV보다 훨씬 높고** 더 먼 파장까지 이어지므로(종종 **~900 nm**), **필터**를 사용해 관심 파장만 촬영해야 하며, 파장대별 **셔터 속도**는 감도 차이를 반영해야 한다(예: UV 감도는 가시광 대비 **~100배 낮음**). 라이브뷰 **히스토그램**은 노출 판단에 유용하다. UV 촬영에는 **Baader Venus‑U**(~320–380 nm 통과), 가시 범위에는 **Baader UV/IR cut**(~400–680 nm 통과)을 사용했다. 두 필터는 2인치 규격으로 온라인 구매 가능하며, 적절한 **필터 홀더**와 결합해 대부분 렌즈에 장착할 수 있다. 우리는 **커스텀 플라스틱 슬라이더**를 제작해 초점·구도를 거의 바꾸지 않고 **신속 교체**가 가능하도록 했다(CNC G‑code 스크립트 제공 가능). UV 사진에는 **UV 투과 렌즈**가 필요하며, 대부분의 표준 렌즈는 UV를 통과시키지 않는다. 예컨대 표준 **Nikon Nikkor 105 mm**는 **~360 nm**까지 투과하나, 가시–UV 사이 **비(非)아크로매틱**이라 파장대별 **재초점**이 필요하다. **Coastal Optics 60/105 mm** 렌즈는 가시–UV 전 범위에서 **아크로매틱**이며 **300 nm 이하**로도 투과하지만 **매우 고가**다. 과거 **UV 유리**를 사용한 단종 렌즈도 중고로 구할 수 있다(Verhoeven & Schmitt, 2010). 예로 **Novoflex Noflexar 35 mm**, **Nikkor EL 80 mm**(메탈 바디 버전만)가 있으며, **~320 nm**까지 투과하고 **우수한 아크로매틱** 특성을 보인다. 단, **상태 양호**한 제품을 구하는 것이 중요하다. 이후 가시/UV 사진을 다중분광 스택으로 **결합**해 **UV 민감 시각계** 매핑이 가능하다.

### 정렬(Alignment)

다중분광 스택을 구성하는 각 채널은 **정확히 정렬**되어야 한다. 특히 몇 픽셀에 불과한 작은 객체의 색을 측정할 때 필수적이다. 야외에서 필터를 교체하면 카메라가 **미세하게 흔들려** 정렬이 틀어질 수 있으며, **비아크로매틱 렌즈**는 파장대별 **재초점**이 필요해 이미지의 **스케일이 약간 달라지기도** 한다. 툴박스는 다중분광 이미지를 준비할 때 다양한 정렬 옵션을 제공한다. 두 사진을 정렬할 때는 **스펙트럼 감도 평균**이 가장 가까운 채널(예: UV‑blue ↔ visible‑blue)을 사용하는 것이 좋다. 이러한 채널은 **카메라 구성 파일**에 지정되어 있으며, 채널 **추출 순서**도 포함된다. **수동 정렬**은 마우스로 한 이미지를 다른 이미지 위로 드래그해 최적 정합이 되도록 한다.

우리는 또한 **재초점**으로 스케일이 달라진 경우에도 **올바른 스케일**을 찾을 수 있는 **자동 정렬**을 개발했다. 스티칭(stitching)용 정렬 도구들을 평가했으나 **UV‑blue ↔ visible‑blue** 간 정렬이 **불안정**해, 전체 이미지의 **절대차 합**을 최소화하는 **대탐색(exhaustive) 정렬·스케일링 알고리즘**을 구현했다. 알고리즘은 먼저 주어진 오프셋(예: 128 px)에서 3×3 윈도우로 전체 이미지에 대해 **절대 픽셀 차 합**을 계산해 가장 좋은 정렬을 찾고, 그 지점을 중심으로 오프셋을 절반(64 px)으로 줄인다. 이를 오프셋이 1이 될 때까지 반복한다. 그 다음 한 이미지를 **미세 스케일링**(예: 1%)하고 위 정렬을 반복한다. 새 스케일에서 정렬 품질이 좋아지면 같은 방향으로 진행하며 스케일 단계를 절반(0.5%)으로 줄이고, 그렇지 않으면 반대 방향으로 탐색한다. 이렇게 **최적 스케일과 정렬**을 찾는다. 이 알고리즘은 비교적 **느리다**(셋팅에 따라 최신 노트북에서 약 **1분**), 그러나 **수동보다 훨씬 우수한 정렬**을 안정적으로 제공하며, 바람에 흔들리는 잎처럼 장면 내 물체의 움직임이 있어도 잘 작동한다. 단, 자동 정렬에는 충분한 **디테일**이 필요하며, **균일한 면**은 적절하지 않다. 따라서 사용자가 **관심 영역**을 지정해 그 부분만 정렬하도록 하는 옵션을 제공한다. 정렬 후에는 슬라이스 사이를 **플립**하며 시각적으로 품질을 점검한다.

### 매핑 방법 검증(Testing mapping methods)

카메라 기반 콘‑캐치 양자의 정확성을 평가하기 위해, **카메라·렌즈·필터 조합 12종**에 대해 조류, 포유류, 어류, 곤충 등 다양한 **시각계**(blue tit, peafowl, human CIE XYZ, honeybee, ferret, pollack, dogfish 등)에 대한 적합도를 시험했다. 각 종의 **스펙트럼 감도**는 툴박스에 포함되어 있으나, 매핑에 사용 시 해당 출처(본문 내 인용)를 인용해야 한다. 감도 곡선은 필요 시 **1 nm 간격**으로 **선형 보간**하였다. **자연 스펙트럼 데이터베이스**에 대한 모델 적합도와, **카메라 vs 분광복사계**로 동시에 측정한 **색 샘플** 간 비교로 품질을 판단했다.

카메라·렌즈·필터 목록은 부록 Table S1에 정리되어 있으며(그림 3 참조), 채널 표기는 소문자 접두어로 **필터 종류**(예: ‘v’=visible, ‘u’=UV)를, 접미어로 **카메라 센서 채널**(R/G/B)을 나타낸다. **스펙트럼 감도**는 Lovell et al.(2005), Garcia et al.(2014)와 유사하되, 단일 파장의 **모노크로메이터** 사진들을 여러 장 찍는 대신, **광대역 백색광**(eyeColor lamp)을 **콜리메이팅**한 뒤 **융합 실리카 프리즘** 한 쌍으로 분광하여 **무지개 스펙트럼**을 **소결 PTFE 시트**에 투사하고, 이를 **한 장의 사진**으로 찍어 **알려진 스펙트럼 복사조도**(Jeti Specbos 1211 UV 분광복사계 측정)와 결합해 **감도 곡선**을 계산했다. 자세한 방법은 별도 출판 예정이나, 기존 방법과 일치하는 결과를 내고(부록 Table S1, 그림 3) 적합도가 우수하다. 다른 방법(Pike, 2011)으로도 감도를 추정할 수 있으나, **미세하게 다른 반사 스펙트럼**을 가진 **다수의 확산 샘플**이 필요(특히 UV에서 어려움)하며, 감도 곡선이 특정 **함수형태**로 표현된다는 **가정**을 요구하는데(항상 성립하지 않음; 그림 3 참조), 이점이 있다.

**자연 스펙트럼 라이브러리 3,139개**(이 중 2,361개는 **FReD**; Arnold et al., 2010, 나머지는 조류 알·깃털, 곤충, 광물, 나무껍질, 식생 등 미공개 데이터)를 사용해 모델을 생성했다. 라이브러리는 툴박스에 포함되어 있으나, 사용 시 해당 출처(Arnold et al., 2010 및 본 논문)를 인용해야 한다. 모든 스펙트럼은 300–700 nm(blue tit, peafowl, honeybee, ferret) 또는 400–700 nm(human XYZ, pollack, dogfish) 범위에서 **1 nm 간격**, 조명은 **D65**를 사용했다. **삼색·이색·단색** 모델은 **3‑way 상호작용**, **제곱항 없음**, **모델 단순화 없음**으로 적합했고, **사색성**은 **2‑way 상호작용**까지(부록 Table S1). 카메라–분광복사계 비교에는 **파스텔 48색(Royal Langnickel)**을 색차트로 사용했다. 표준 사진용 컬러차트는 대개 **UV 반사**가 좋지 않아(아마도 **퇴색 방지** 목적), 다양한 **UV 반사 피크**를 가진 파스텔을 사용했다(그림 4). 이는 **복잡하고 채도가 높은 색**을 포함하므로 자연 스펙트럼에 비해 **보수적(엄격)**인 테스트다. 파스텔 반사 스펙트럼은 위 분광복사계로 측정했고, 사진은 **D65 모사** eyeColor 램프로 촬영했으며, **20%·80% Spectralon**으로 이미지 표준화했다.

### 매핑 결과(Mapping results)

자연 스펙트럼 데이터베이스에 대해 **카메라 콘‑캐치 ↔ 수용체 콘‑캐치** 적합도의 **평균 R²**는 **0.999**(중앙값 > 0.999, 최소 0.996)였다. 이는 **다항식 콘 매핑**으로 **카메라 색 측정**을 **콘‑캐치 양자**로 신뢰성 있게 변환할 수 있음을 시사한다. **복잡한 파스텔 색**에 대해 **카메라 vs 분광복사계** 콘‑캐치 비교도 우수했으며, **평균 적합도 0.981**(중앙값 0.983, 최소 0.951; 부록 Table S1, 그림 5). 즉, 이 매핑 접근은 **분광측정 기반** 접근과 비교해도 **높은 정확도**를 보인다.

그림 5는 **파랑박새(blue tit)** 콘‑캐치 추정을 예로 들며, **두 필터·5채널**(vR, vG, vB, uB, uR)과 **네 필터·7채널**(rR, gR, gG, bG, bB, uB, uR)의 비교를 보여준다. **두 필터**만으로도 **탁월한 적합**을 보이지만, 추가 채널은 **중간파장(M)** 대역의 **스펙트럼 분할**을 다소 개선해 해당 채널 적합을 향상시킨다. **형광(fluorescent)** 두 샘플은 **단파 흡수–장파 방출**을 보여 **반사율 0–100%** 범위를 넘는 값을 보였으며, 툴박스가 이런 **범위 밖 값**도 처리할 수 있음을 보여준다.

---

## 이미지 분석(Image analysis)

대부분의 측정에는 **Batch Multispectral Image Analysis** 도구 사용을 권장한다. 이를 통해 관련 이미지들을 **정확히 동일한 설정**으로 측정할 수 있고, 큰 데이터셋도 **자동 처리**로 컴퓨터에 맡길 수 있다. 사용자는 `.mspec`(링크된 RAW가 동일 폴더 내)들이 들어 있는 디렉터리를 지정하고, 원하는 **시각계 매핑**(또는 매핑 없음) 옵션을 선택한다. `.mspec`에 ROI(사각형, 다각형 등; 그림 1)가 저장되어 있다면 개별 측정 또는 지정에 따라 **풀링**(겹치는 영역은 **합집합**)이 가능하며, ROI가 없다면 **전체 이미지**를 측정한다. 스케일 바가 있다면 모든 이미지를 **동일 해상도(픽셀/단위길이)**로 자동 보정한다(대부분의 **패턴 분석**에 필요).

우리는 **고속 푸리에(Band‑pass) 필터링** 기반의 몇 가지 **패턴 분석** 도구를 제공한다. 이 분석은 동물 무늬 측정에 점점 널리 쓰이며(e.g., Godfrey, Lythgoe & Rumball, 1987; Stoddard & Stevens, 2010), 수많은 척추/무척추에서의 **저수준 신경생리학적 공간 처리**에 대한 이해를 느슨하게 반영한다. 간단히 말해, 이미지를 **여러 공간주파수 대역**으로 필터링한 뒤, 각 대역의 **에너지**(필터링 이미지의 **표준편차**)를 측정하는 **입도(granularity) 분석**을 수행한다(Chiao et al., 2009; Stoddard & Stevens, 2010; 상세는 가이드). 툴박스는 무늬 **크기, 대비, 다양성** 등에 대응하는 **기술통계**를 제공하거나, 두 객체·샘플 간 **쌍대 패턴 차이** 계산도 수행한다. 또한 **색 분석**으로 **수용체 잡음 기반 판별 모델**을 제공하여, 샘플 쌍 간 **JND**를 계산한다(Vorobyev & Osorio, 1998; Siddiqi et al., 2004). 이를 통해 두 샘플이 특정 시각계에서 **구분 가능**한지 평가할 수 있다. 색·패턴 분석 도구의 자세한 내용은 **사용자 가이드**에 기술했다.

---

## 논의(Discussion)

시각 생태학(visual ecology) 분야는 빠르게 성장 중이다(Cronin et al., 2014). 디지털 이미징의 보급으로 동물·식물의 **채색, 신호, 위장**에 관한 다양한 가설을 **거의 모든 연구자**가 시험할 수 있게 되었다. 또한 이미지 분석은 의학, 법과학 등 **다양한 영역**에서 사용된다. 그러나 디지털 사진은 **광휘에 대해 비선형**이며, 다양한 **보정 단계**가 필요하므로, 보정 없이 **픽셀 값**으로부터 **정량 측정**을 수행해서는 안 된다. 일부 저자와 심사자는 여전히 이러한 문제를 인지하지 못한 채, **포토샵 등**에서 **비표준화 이미지**의 **RGB 값**을 테스트하는 등의 실수를 범하고, 대상 종의 **시각계**를 고려하지 않는 경우도 빈번하다. 지금까지 **선형화 과정**은 대체로 **고가의 특수 장비**와 **코딩 기술**을 요구했다(Barnard & Funt, 2002; Stevens et al., 2007; Garcia et al., 2013). 우리의 이미지 처리 툴박스는 **RAW 파일에서 선형 이미지 추출**(Chakrabarti et al., 2009; Akkaynak et al., 2014; Coffin, 2015)로 이러한 장벽을 낮춘다.

또한 툴박스는 이전 방법(Stevens et al., 2007)보다 **유연한 조명 보정**을 제공한다. **두 개 이상**의 회색 기준을 사용해 **반사율**과 함께 **블랙 포인트**까지 추정하여 **저수준 베일 글레어**(McCann & Rizzi, 2007)를 제어하고, **약간 불투명한 매질**(안개, 흐린 물) 너머나 **투명 표면**(고요한 물, 유리) 너머의 사진에서도 측정이 가능하게 한다(단, 반사가 **균일**해야 하며, 기준은 대상 **인접**에 두어야 함).

이전 이미지 분석 연구는 거의 예외 없이 **8‑bit** 이미지를 사용했는데, 이는 특히 **선형 이미지**에서 **동적 범위**와 **정밀도**를 심각하게 제한한다. 자연 장면의 반사율 분포는 대체로 **로그 분포**이므로, 선형 8‑bit에서 **대부분 픽셀**은 255 중 약 **30–40** 하위에 몰린다. 또한 이전 표준화 방법은 회색 기준 대비 **100% 초과 반사율**을 허용하지 못했는데, 이는 **광택** 표면(잎, 젖은 자갈), **형광**, **발광/투광**과 같은 자연 장면에서 흔하다(예: 하늘 배경으로 본 잎). 우리는 이미지를 **16‑bit**로 가져와 카메라의 **전체 동적 범위**를 보존하고, 표준화와 이후 처리를 **32‑bit 부동소수점**에서 수행함으로써 **100% 초과 반사율**을 허용해 **데이터 손실/포화** 문제를 해소했다. 이는 **광택·형광** 표면이나 **기준보다 적은 조명**을 받는 회색 기준 상황(예: 얼룩진 그림자)에서도 측정이 가능하게 한다.

32‑bit 이미지를 그대로 저장하면 다중분광 스택이 **수백 MB**에 이르러 저장 공간이 비효율적이다. 그러나 RAW에서 **표준화/콘‑캐치 스택**을 **빠르게 재구성**할 수 있으므로, 거대 파일을 저장하는 대신 필요한 정보를 모두 담은 **경량 `.mspec`** 파일만 저장한다. RAW에서 바로 로딩하면 **잘못된 변환**이나 **중복 변환**을 적용하기 어렵고, RAW는 **백업·아카이브**에도 적합하다(후처리 누락, 메타데이터 보존).

많은 시각 생태학자는 **비인간 시각계** 가설을 다룬다. 본 툴박스는 **카메라 색 → 임의의 시각계 콘‑캐치** 매핑을 제공한다(여러 **모델 시각계** 포함; 데이터베이스 확대 예정). 콘 매핑의 두 전제는, (i) 사진이 **목표 시각계의 감도 범위**를 포괄해야 한다(예: 조류·파충류·다수 곤충은 **가시+UV**), (ii) 카메라의 **스펙트럼 감도**가 알려져야 한다(Lovell et al., 2005; Stevens et al., 2007; Pike, 2011; Garcia et al., 2014). 감도 결정은 여전히 특수 장비를 요구하며, 이를 더 쉽게 만드는 추가 연구나, 제조사의 **감도 정보 공개**가 요구된다. 우리는 지금까지 특성화한 **카메라‑렌즈‑필터** 조합의 감도 곡선을 소프트웨어에 포함했다. 현재 작업은 최소한 **Nikon D7000**과 **Canon D400**에서는 **동일 메이커·모델**, **동일 렌즈·필터**, **동일 풀 스펙트럼 변환** 조건이면 **장치 간 변동**이 크지 않음을 시사한다(그림 3). 따라서 동일 셋업이라면 제공 곡선을 사용할 수 있으나, 더 많은 셋업이 특성화되기 전까지는 어느 정도 **주의**가 필요하다. 이 전제들이 충족되면 툴박스는 다중 사진을 **정렬된 다중분광 스택**으로 결합하고, 이를 **동물 콘‑캐치 양자**로 변환한다.

이전 연구는 **카메라 RGB → 인간 LMS** 콘‑캐치를 **다항식 매핑**으로 성공적으로 변환할 수 있음을 보였고(Lovell et al., 2005; Stevens et al., 2007), **비인간** 콘‑캐치로도 확장 가능함을 보였다(Stevens & Cuthill, 2006; Pike, 2011; Stevens, Lown & Wood, 2014b). 우리는 **더 많은 채널**을 사용할 때도 이러한 모델이 신뢰성 있게 콘‑캐치를 복원하며, 필터/채널을 늘려 **스펙트럼 해상도**를 올리는 것은 **정확도 향상에 한계수익 체감**이 있음을 보였다(그림 5). 이는 현재 **매우 고가**이고 **낮은 해상도/느린 캡처**를 보이는 **초분광(hyperspectral)** 이미징이, **두 개 필터만 갖춘 소비자용 카메라** 대비 **콘‑캐치 추정**에서 주는 이점이 아직은 크지 않음을 시사한다.

마지막으로, 툴박스는 선택된 영역의 **색, 휘도, 패턴**을 측정하고, 선택한 샘플 간 **차이**를 모델링하는 **통합 측정 도구**를 제공한다. 오픈 소스 코드와 플랫폼(ImageJ: Schneider et al., 2012; R: R Core Team, 2013)으로 **사용자 친화적 패키지**를 공개함으로써, 더 많은 연구자가 디지털 카메라로 **객관적 측정**을 수행하고, 이미지 분석의 **막대한 잠재력**을 활용하여 생물학의 광범한 질문을 다루기를 기대한다.

---

## 감사의 글(Acknowledgements)

Jared Wilson‑Aggarwal, Lina Maria Arenas, Sarah Paul, Alice Lown, Emmanuelle Briolat, Samuel Smithers, Sara Mynott 및 Sensory Ecology 그룹의 다른 구성원들에게 툴박스에 대한 귀중한 피드백, 테스트, 디버깅에 감사한다. James Higham과 두 명의 익명 심사자에게도 건설적인 조언에 감사드린다. J.T.와 M.S.는 M.S.에게 배정된 BBSRC(영국 생명공학·생물과학 연구위원회) 그랜트 **BB/J018309/1**, **BB/L017709/1**과, M.S.에게 부여된 **BBSRC David Phillips Research Fellowship (BB/G022887/1)**의 지원을 받았다.

## 데이터 접근성(Data accessibility)

사용자 가이드, 선형화 데이터, 카메라 콘‑캐치 성능 측정을 위한 색 샘플 사진은 **Dryad Digital Repository**에서 이용 가능하다: [http://dx.doi.org/10.5061/dryad.pj073](http://dx.doi.org/10.5061/dryad.pj073)
툴박스와 가이드의 최신 버전은 **[www.jolyon.co.uk](http://www.jolyon.co.uk)** 또는 **[www.sensoryecology.com**에서](http://www.sensoryecology.com**에서) 내려받을 수 있다.

---

### 그림 캡션(Figure captions)

**그림 1. 다중분광 이미지 준비 예시.** 가시광 및 UV로 촬영된 장면으로부터 **정규화·정렬된 스택**을 생성하는 주요 단계를 요약한다. 결과 이미지는 정량 측정에 사용하거나, 카메라 감도가 알려진 경우 **동물 콘‑캐치 양자**로 변환할 수 있다. 마지막 단계는 **관심 영역(ROI)** 선택을 보여준다. 본 예시에서 ‘p’는 꽃잎(petal)을 의미하며, 각 영역을 개별 측정하거나 결합하여 측정할 수 있다. 채널 이름은 접두어로 **필터 유형**(예: ‘v’=visible, ‘u’=UV), 접미어로 **카메라 채널**(R/G/B)을 표시한다. 추가 필터로 더 많은 조합을 만들 수 있다.

**그림 2. Nikon D7000의 카메라 선형 응답 예시.** **정규화된 기대 반사율(x축)** 대비 **표준별 관측 픽셀 평균(y축)**을 도시했다. 이 정규화는 다양한 조리개·셔터에서의 **사진 내·사진 간 선형성**을 동시 검정하며, y축에 **실제 픽셀 값**을 유지하므로 특정 픽셀 영역에서의 **하드웨어 비선형성**도 감지할 수 있다. 에러바는 평균 ± 표준편차. 포인트 밝기는 조리개와 함께 스케일된다.

**그림 3. 동일 장비 셋업 간 스펙트럼 감도.** 실선과 점선은 동일 장비(풀 스펙트럼 변환 포함)를 사용한 **두 셋업**의 스펙트럼 감도를 나타낸다. **매우 유사**한 감도 곡선은, 동일한 메이커·모델·렌즈·필터·변환 조건이라면 **상호 감도 곡선 공유**가 가능함을 시사한다.

**그림 4. 색 샘플 측정.** **파스텔 48색**을 사용해 카메라와 분광복사계의 **콘‑캐치 양자**를 비교했다. (a) 일반 가시광 사진, (b) **의사색(false colour)** 조합(vG, vB, uR). 두 이미지는 **32‑bit 선형·정규화 이미지**를 **제곱근 변환**하여 저동적 범위 매체에 맞춰 표시했다. 표준 컬러차트는 **UV 반사**가 좋지 않은 반면, 파스텔은 **다양한 UV 반사 피크**를 가진다. (b)에서 파랗게 보이는 샘플은 **녹/청 대비 UV 피크**를 가진다.

**그림 5. 파랑박새 콘‑캐치 양자 추정 비교(카메라 vs 분광복사계).** 왼쪽: **Canon 7D, 2필터·5채널**(vR, vG, vB, uB, uR). 오른쪽: **동일 카메라, 4필터·7채널**(rR, gR, gG, bG, bB, uB, uR). 음영은 표준오차. **두 필터**만으로도 **매우 우수**하지만, 추가 채널은 **중간파장** 채널의 적합을 개선한다. 두 샘플은 **형광**을 나타내며, **단파 흡수–장파 방출**로 **100% 초과 반사율**을 보였고, 툴박스가 이러한 값도 처리함을 보여준다.

---

*교신저자: [jt@jolyon.co.uk](mailto:jt@jolyon.co.uk)
© 2015 저자. 본 논문은 Creative Commons Attribution License(CC BY)에 따라 원저작물 표기 조건으로 자유 이용, 배포, 복제가 허용된다.*
